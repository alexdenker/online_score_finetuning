{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5881ed34",
   "metadata": {},
   "source": [
    "# Online Finetuning using the adjoint SDE\n",
    "\n",
    "We are using the technique proposed in:\n",
    "1. Li et al.: Scalable Gradients for Stochastic Differential Equations (https://arxiv.org/pdf/2001.01328.pdf)\n",
    "2. Kidger et al.:Efficient and Accurate Gradients for Neural SDEs (https://arxiv.org/pdf/2105.13493.pdf)\n",
    "\n",
    "and implemented in the torchsde (see the documentation https://github.com/google-research/torchsde/blob/master/DOCUMENTATION.md#adjoints). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c776aa0b",
   "metadata": {},
   "source": [
    "## Specific example \n",
    "\n",
    "We use a score-based model trained on the MNIST dataset with $n = 784$ dimensions. We are looking at a compressed sensing example, i.e., $y = A x + \\eta$ with a $m \\times n, m << n$ matrix with $A_{i,j} \\sim \\mathcal{N}(0,1/m)$. The matrix $A$ is created once and then fixed for the experiment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb546105",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adenker/anaconda3/envs/diffusion/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchsde\n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import os \n",
    "import yaml \n",
    "\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms \n",
    "from torchvision.utils import make_grid, save_image\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm \n",
    "\n",
    "from src import TinyUnet, VPSDE, BaseSampler, Euler_Maruyama_sde_predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e2b6937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TinyUnet(\n",
       "  (init_conv): ConvBnSiLu(\n",
       "    (module): Sequential(\n",
       "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): SiLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (time_embed): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (1): SiLU()\n",
       "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "  )\n",
       "  (encoder_blocks): ModuleList(\n",
       "    (0): EncoderBlock(\n",
       "      (conv0): Sequential(\n",
       "        (0): ResidualBottleneck(\n",
       "          (branch1): Sequential(\n",
       "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
       "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ConvBnSiLu(\n",
       "              (module): Sequential(\n",
       "                (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (branch2): Sequential(\n",
       "            (0): ConvBnSiLu(\n",
       "              (module): Sequential(\n",
       "                (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
       "            (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (3): ConvBnSiLu(\n",
       "              (module): Sequential(\n",
       "                (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (channel_shuffle): ChannelShuffle()\n",
       "        )\n",
       "        (1): ResidualBottleneck(\n",
       "          (branch1): Sequential(\n",
       "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
       "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ConvBnSiLu(\n",
       "              (module): Sequential(\n",
       "                (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (branch2): Sequential(\n",
       "            (0): ConvBnSiLu(\n",
       "              (module): Sequential(\n",
       "                (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
       "            (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (3): ConvBnSiLu(\n",
       "              (module): Sequential(\n",
       "                (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (channel_shuffle): ChannelShuffle()\n",
       "        )\n",
       "        (2): ResidualBottleneck(\n",
       "          (branch1): Sequential(\n",
       "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
       "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ConvBnSiLu(\n",
       "              (module): Sequential(\n",
       "                (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (branch2): Sequential(\n",
       "            (0): ConvBnSiLu(\n",
       "              (module): Sequential(\n",
       "                (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
       "            (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (3): ConvBnSiLu(\n",
       "              (module): Sequential(\n",
       "                (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (channel_shuffle): ChannelShuffle()\n",
       "        )\n",
       "        (3): ResidualBottleneck(\n",
       "          (branch1): Sequential(\n",
       "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
       "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ConvBnSiLu(\n",
       "              (module): Sequential(\n",
       "                (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (branch2): Sequential(\n",
       "            (0): ConvBnSiLu(\n",
       "              (module): Sequential(\n",
       "                (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
       "            (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (3): ConvBnSiLu(\n",
       "              (module): Sequential(\n",
       "                (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (channel_shuffle): ChannelShuffle()\n",
       "        )\n",
       "      )\n",
       "      (time_mlp): TimeMLP(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "          (1): SiLU()\n",
       "          (2): Linear(in_features=128, out_features=64, bias=True)\n",
       "        )\n",
       "        (act): SiLU()\n",
       "      )\n",
       "      (conv1): ResidualDownsample(\n",
       "        (branch1): Sequential(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ConvBnSiLu(\n",
       "            (module): Sequential(\n",
       "              (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (branch2): Sequential(\n",
       "          (0): ConvBnSiLu(\n",
       "            (module): Sequential(\n",
       "              (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64)\n",
       "          (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): ConvBnSiLu(\n",
       "            (module): Sequential(\n",
       "              (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (channel_shuffle): ChannelShuffle()\n",
       "      )\n",
       "    )\n",
       "    (1): EncoderBlock(\n",
       "      (conv0): Sequential(\n",
       "        (0): ResidualBottleneck(\n",
       "          (branch1): Sequential(\n",
       "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
       "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ConvBnSiLu(\n",
       "              (module): Sequential(\n",
       "                (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (branch2): Sequential(\n",
       "            (0): ConvBnSiLu(\n",
       "              (module): Sequential(\n",
       "                (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
       "            (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (3): ConvBnSiLu(\n",
       "              (module): Sequential(\n",
       "                (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (channel_shuffle): ChannelShuffle()\n",
       "        )\n",
       "        (1): ResidualBottleneck(\n",
       "          (branch1): Sequential(\n",
       "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
       "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ConvBnSiLu(\n",
       "              (module): Sequential(\n",
       "                (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (branch2): Sequential(\n",
       "            (0): ConvBnSiLu(\n",
       "              (module): Sequential(\n",
       "                (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
       "            (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (3): ConvBnSiLu(\n",
       "              (module): Sequential(\n",
       "                (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (channel_shuffle): ChannelShuffle()\n",
       "        )\n",
       "        (2): ResidualBottleneck(\n",
       "          (branch1): Sequential(\n",
       "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
       "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ConvBnSiLu(\n",
       "              (module): Sequential(\n",
       "                (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (branch2): Sequential(\n",
       "            (0): ConvBnSiLu(\n",
       "              (module): Sequential(\n",
       "                (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
       "            (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (3): ConvBnSiLu(\n",
       "              (module): Sequential(\n",
       "                (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (channel_shuffle): ChannelShuffle()\n",
       "        )\n",
       "        (3): ResidualBottleneck(\n",
       "          (branch1): Sequential(\n",
       "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
       "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ConvBnSiLu(\n",
       "              (module): Sequential(\n",
       "                (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (branch2): Sequential(\n",
       "            (0): ConvBnSiLu(\n",
       "              (module): Sequential(\n",
       "                (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
       "            (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (3): ConvBnSiLu(\n",
       "              (module): Sequential(\n",
       "                (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (channel_shuffle): ChannelShuffle()\n",
       "        )\n",
       "      )\n",
       "      (time_mlp): TimeMLP(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): SiLU()\n",
       "          (2): Linear(in_features=256, out_features=128, bias=True)\n",
       "        )\n",
       "        (act): SiLU()\n",
       "      )\n",
       "      (conv1): ResidualDownsample(\n",
       "        (branch1): Sequential(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ConvBnSiLu(\n",
       "            (module): Sequential(\n",
       "              (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (branch2): Sequential(\n",
       "          (0): ConvBnSiLu(\n",
       "            (module): Sequential(\n",
       "              (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128)\n",
       "          (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): ConvBnSiLu(\n",
       "            (module): Sequential(\n",
       "              (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (channel_shuffle): ChannelShuffle()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder_blocks): ModuleList(\n",
       "    (0): DecoderBlock(\n",
       "      (upsample): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "      (conv0): Sequential(\n",
       "        (0): ResidualBottleneck(\n",
       "          (branch1): Sequential(\n",
       "            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ConvBnSiLu(\n",
       "              (module): Sequential(\n",
       "                (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (branch2): Sequential(\n",
       "            (0): ConvBnSiLu(\n",
       "              (module): Sequential(\n",
       "                (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "            (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (3): ConvBnSiLu(\n",
       "              (module): Sequential(\n",
       "                (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (channel_shuffle): ChannelShuffle()\n",
       "        )\n",
       "        (1): ResidualBottleneck(\n",
       "          (branch1): Sequential(\n",
       "            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ConvBnSiLu(\n",
       "              (module): Sequential(\n",
       "                (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (branch2): Sequential(\n",
       "            (0): ConvBnSiLu(\n",
       "              (module): Sequential(\n",
       "                (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "            (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (3): ConvBnSiLu(\n",
       "              (module): Sequential(\n",
       "                (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (channel_shuffle): ChannelShuffle()\n",
       "        )\n",
       "        (2): ResidualBottleneck(\n",
       "          (branch1): Sequential(\n",
       "            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ConvBnSiLu(\n",
       "              (module): Sequential(\n",
       "                (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (branch2): Sequential(\n",
       "            (0): ConvBnSiLu(\n",
       "              (module): Sequential(\n",
       "                (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "            (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (3): ConvBnSiLu(\n",
       "              (module): Sequential(\n",
       "                (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (channel_shuffle): ChannelShuffle()\n",
       "        )\n",
       "        (3): ResidualBottleneck(\n",
       "          (branch1): Sequential(\n",
       "            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ConvBnSiLu(\n",
       "              (module): Sequential(\n",
       "                (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (branch2): Sequential(\n",
       "            (0): ConvBnSiLu(\n",
       "              (module): Sequential(\n",
       "                (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "            (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (3): ConvBnSiLu(\n",
       "              (module): Sequential(\n",
       "                (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (channel_shuffle): ChannelShuffle()\n",
       "        )\n",
       "      )\n",
       "      (time_mlp): TimeMLP(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): SiLU()\n",
       "          (2): Linear(in_features=256, out_features=128, bias=True)\n",
       "        )\n",
       "        (act): SiLU()\n",
       "      )\n",
       "      (conv1): ResidualBottleneck(\n",
       "        (branch1): Sequential(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ConvBnSiLu(\n",
       "            (module): Sequential(\n",
       "              (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (branch2): Sequential(\n",
       "          (0): ConvBnSiLu(\n",
       "            (module): Sequential(\n",
       "              (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
       "          (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): ConvBnSiLu(\n",
       "            (module): Sequential(\n",
       "              (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (channel_shuffle): ChannelShuffle()\n",
       "      )\n",
       "    )\n",
       "    (1): DecoderBlock(\n",
       "      (upsample): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "      (conv0): Sequential(\n",
       "        (0): ResidualBottleneck(\n",
       "          (branch1): Sequential(\n",
       "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
       "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ConvBnSiLu(\n",
       "              (module): Sequential(\n",
       "                (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (branch2): Sequential(\n",
       "            (0): ConvBnSiLu(\n",
       "              (module): Sequential(\n",
       "                (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
       "            (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (3): ConvBnSiLu(\n",
       "              (module): Sequential(\n",
       "                (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (channel_shuffle): ChannelShuffle()\n",
       "        )\n",
       "        (1): ResidualBottleneck(\n",
       "          (branch1): Sequential(\n",
       "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
       "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ConvBnSiLu(\n",
       "              (module): Sequential(\n",
       "                (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (branch2): Sequential(\n",
       "            (0): ConvBnSiLu(\n",
       "              (module): Sequential(\n",
       "                (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
       "            (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (3): ConvBnSiLu(\n",
       "              (module): Sequential(\n",
       "                (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (channel_shuffle): ChannelShuffle()\n",
       "        )\n",
       "        (2): ResidualBottleneck(\n",
       "          (branch1): Sequential(\n",
       "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
       "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ConvBnSiLu(\n",
       "              (module): Sequential(\n",
       "                (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (branch2): Sequential(\n",
       "            (0): ConvBnSiLu(\n",
       "              (module): Sequential(\n",
       "                (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
       "            (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (3): ConvBnSiLu(\n",
       "              (module): Sequential(\n",
       "                (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (channel_shuffle): ChannelShuffle()\n",
       "        )\n",
       "        (3): ResidualBottleneck(\n",
       "          (branch1): Sequential(\n",
       "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
       "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ConvBnSiLu(\n",
       "              (module): Sequential(\n",
       "                (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (branch2): Sequential(\n",
       "            (0): ConvBnSiLu(\n",
       "              (module): Sequential(\n",
       "                (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
       "            (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (3): ConvBnSiLu(\n",
       "              (module): Sequential(\n",
       "                (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (channel_shuffle): ChannelShuffle()\n",
       "        )\n",
       "      )\n",
       "      (time_mlp): TimeMLP(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "          (1): SiLU()\n",
       "          (2): Linear(in_features=128, out_features=64, bias=True)\n",
       "        )\n",
       "        (act): SiLU()\n",
       "      )\n",
       "      (conv1): ResidualBottleneck(\n",
       "        (branch1): Sequential(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ConvBnSiLu(\n",
       "            (module): Sequential(\n",
       "              (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (branch2): Sequential(\n",
       "          (0): ConvBnSiLu(\n",
       "            (module): Sequential(\n",
       "              (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
       "          (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): ConvBnSiLu(\n",
       "            (module): Sequential(\n",
       "              (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (channel_shuffle): ChannelShuffle()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (mid_block): Sequential(\n",
       "    (0): ResidualBottleneck(\n",
       "      (branch1): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ConvBnSiLu(\n",
       "          (module): Sequential(\n",
       "            (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (branch2): Sequential(\n",
       "        (0): ConvBnSiLu(\n",
       "          (module): Sequential(\n",
       "            (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "        (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ConvBnSiLu(\n",
       "          (module): Sequential(\n",
       "            (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (channel_shuffle): ChannelShuffle()\n",
       "    )\n",
       "    (1): ResidualBottleneck(\n",
       "      (branch1): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ConvBnSiLu(\n",
       "          (module): Sequential(\n",
       "            (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (branch2): Sequential(\n",
       "        (0): ConvBnSiLu(\n",
       "          (module): Sequential(\n",
       "            (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "        (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ConvBnSiLu(\n",
       "          (module): Sequential(\n",
       "            (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (channel_shuffle): ChannelShuffle()\n",
       "    )\n",
       "    (2): ResidualBottleneck(\n",
       "      (branch1): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ConvBnSiLu(\n",
       "          (module): Sequential(\n",
       "            (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (branch2): Sequential(\n",
       "        (0): ConvBnSiLu(\n",
       "          (module): Sequential(\n",
       "            (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "        (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ConvBnSiLu(\n",
       "          (module): Sequential(\n",
       "            (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (channel_shuffle): ChannelShuffle()\n",
       "    )\n",
       "  )\n",
       "  (final_conv): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load pre trained score-based model (trained with score matching)\n",
    "\n",
    "base_path = \"model_weights\"\n",
    "\n",
    "with open(os.path.join(base_path, \"report.yaml\"), \"r\") as f:\n",
    "    cfg_dict = yaml.safe_load(f)\n",
    "\n",
    "sde = VPSDE(beta_min=cfg_dict[\"diffusion\"][\"beta_min\"], \n",
    "            beta_max=cfg_dict[\"diffusion\"][\"beta_max\"]\n",
    "            )\n",
    "\n",
    "model = TinyUnet(\n",
    "            marginal_prob_std=sde.marginal_prob_std, \n",
    "            time_embedding_dim=cfg_dict[\"model\"][\"time_embedding_dim\"],\n",
    "            max_period=cfg_dict[\"model\"][\"max_period\"],\n",
    "            in_channels=cfg_dict[\"model\"][\"in_channels\"],\n",
    "            out_channels=cfg_dict[\"model\"][\"out_channels\"],\n",
    "            base_dim=cfg_dict[\"model\"][\"base_dim\"],\n",
    "            dim_mults=cfg_dict[\"model\"][\"dim_mults\"])\n",
    "model.load_state_dict(torch.load(\"model_weights/model.pt\"))\n",
    "model.to(\"cuda\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e55b6b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data and create forward operator\n",
    "\n",
    "val_dataset = MNIST(root=\"./mnist_data\",\n",
    "                        train=False,\n",
    "                        download=True,\n",
    "                        transform = transforms.ToTensor()\n",
    "                        )\n",
    "\n",
    "\n",
    "x_gt = val_dataset[0][0].unsqueeze(0).to(\"cuda\")\n",
    "\n",
    "m = x_gt.numel()/2\n",
    "A = torch.randn([int(m), int(x_gt.numel())])/torch.sqrt(torch.tensor(m))\n",
    "A = A.to(\"cuda\")\n",
    "\n",
    "def Afwd(x, A=A):\n",
    "\n",
    "    tmp = x.view(x.shape[0], -1)\n",
    "\n",
    "    return torch.matmul(tmp, A.T)\n",
    "\n",
    "def Abwd(y, A=A):\n",
    "\n",
    "    tmp = torch.matmul(y, A)\n",
    "\n",
    "    return tmp.view(tmp.shape[0], 1, 28, 28)\n",
    "\n",
    "y = Afwd(x_gt)\n",
    "y_noise = y + 0.01*torch.mean(y)*torch.rand_like(y)\n",
    "ATy = Abwd(y_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97bc641d-b7d2-411d-853b-cee8d5ee1c63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2)\n",
    "\n",
    "ax1.imshow(x_gt.cpu()[0,0,:,:])\n",
    "ax1.set_title(\"GT\")\n",
    "\n",
    "ax2.imshow(ATy.cpu()[0,0,:,:])\n",
    "ax2.set_title(\"A*(y)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdb981e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define Ito SDE\n",
    "# define the reverse SDE for sampling\n",
    "# dx = (f(x,t) - g(t)^2 s(x,t) - g(t)^2 h(x, t)) dt+ g(t) dw\n",
    "# However, torchsde can only deal with increasing time sequences\n",
    "# so, we have to look at dx = - (f(x, 1-t) - g(1-t)^2 s(x, 1-t) - g(1-t)^2 h(x, 1-t)) dt + g(1-t) dw \n",
    "# s pretrained score, h finetune score\n",
    "# further, we have to audgment the SDE to output || h(x,t) || (i.e. add one extra state with g(t)=0)\n",
    "\n",
    "class SDE(torch.nn.Module):\n",
    "    noise_type = 'diagonal'\n",
    "    sde_type = 'ito'\n",
    "\n",
    "    def __init__(self, model, sde, y_noise):\n",
    "        super().__init__()\n",
    "        self.noise_type = \"diagonal\"\n",
    "        self.sde_type = \"ito\"\n",
    "\n",
    "        self.model = model \n",
    "        self.sde = sde \n",
    "        self.cond_model = TinyUnet(\n",
    "            marginal_prob_std=sde.marginal_prob_std, \n",
    "            time_embedding_dim=cfg_dict[\"model\"][\"time_embedding_dim\"],\n",
    "            max_period=cfg_dict[\"model\"][\"max_period\"],\n",
    "            in_channels=1,\n",
    "            out_channels=cfg_dict[\"model\"][\"out_channels\"],\n",
    "            base_dim=16,\n",
    "            dim_mults=[1,2])\n",
    "        self.cond_model.to(\"cuda\")\n",
    "        self.cond_model.train() \n",
    "\n",
    "        self.y_noise = y_noise\n",
    "    # Drift\n",
    "    def f(self, t, y):\n",
    "        y = y[:, :-1]\n",
    "\n",
    "        #print(1.0 - t)\n",
    "        ones_vec = torch.ones(y.shape[0], device=y.device)\n",
    "        t = ones_vec * t\n",
    "        \n",
    "        s_pretrained = self.model(y.view(y.shape[0], 1, 28,28), 1.0 - t)\n",
    "        \n",
    "        cond = torch.repeat_interleave(self.y_noise,  dim=0, repeats=y.shape[0])\n",
    "        log_grad = Abwd(Afwd(y.view(y.shape[0], 1, 28,28)) - cond)\n",
    "        s_new = self.cond_model(log_grad, 1.0 - t)\n",
    "\n",
    "        s = s_pretrained + s_new\n",
    "\n",
    "        drift, diffusion = self.sde.sde(y.view(y.shape[0], 1, 28,28), 1.0 - t)\n",
    "\n",
    "        mu = drift - diffusion[:, None, None, None].pow(2)*s\n",
    "\n",
    "        beta_t = self.sde.beta_0 + (1.0 - t) * (self.sde.beta_1 - self.sde.beta_0)\n",
    "        f_sq = beta_t.unsqueeze(1)*(s_new ** 2).sum(dim=(1,2,3)).unsqueeze(1)\n",
    "\n",
    "        drift = -mu.view(y.shape[0], -1)\n",
    "        \n",
    "        return torch.cat([drift, f_sq], dim=1)\n",
    "\n",
    "    # Diffusion\n",
    "    def g(self, t, y):\n",
    "        y = y[:, :-1]\n",
    "        ones_vec = torch.ones(y.shape[0], device=y.device)\n",
    "        t = ones_vec * t\n",
    "        drift, diffusion = self.sde.sde(y.view(y.shape[0], 1, 28,28), 1.0 - t)\n",
    "\n",
    "        diffusion_rep = diffusion[:,None].repeat(1, y.shape[-1])\n",
    "        return torch.cat([diffusion_rep, torch.zeros((y.shape[0], 1), device=y.device)], dim=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72febaf-b5b9-4a06-93ab-955dc50533af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.parameters at 0x7f5118790ba0>\n",
      "PARAMETERS IN SDE MODEL:  1134326\n",
      "PARAMETERS IN pretrained model:  960481\n",
      "PARAMETERS IN finetune:  173845\n",
      "torch.Size([12, 1, 28, 28])\n",
      "tensor(59.6494, device='cuda:0', grad_fn=<MulBackward0>) tensor(0., device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "59.64944076538086\n",
      "TIME FOR ONE GRADIENT STEP:  35.87791109085083 s\n",
      "tensor(54.5250, device='cuda:0', grad_fn=<MulBackward0>) tensor(0.1345, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "54.65946578979492\n",
      "TIME FOR ONE GRADIENT STEP:  34.61878252029419 s\n",
      "tensor(56.1517, device='cuda:0', grad_fn=<MulBackward0>) tensor(0.5357, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "56.68743133544922\n",
      "TIME FOR ONE GRADIENT STEP:  34.69671702384949 s\n",
      "tensor(55.7506, device='cuda:0', grad_fn=<MulBackward0>) tensor(1.1612, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "56.91179656982422\n",
      "TIME FOR ONE GRADIENT STEP:  34.99364161491394 s\n",
      "tensor(55.5179, device='cuda:0', grad_fn=<MulBackward0>) tensor(1.8229, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "57.34079360961914\n",
      "TIME FOR ONE GRADIENT STEP:  34.83220601081848 s\n",
      "tensor(45.8925, device='cuda:0', grad_fn=<MulBackward0>) tensor(2.6950, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "48.58740997314453\n",
      "TIME FOR ONE GRADIENT STEP:  34.457342863082886 s\n",
      "tensor(47.2409, device='cuda:0', grad_fn=<MulBackward0>) tensor(3.1979, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "50.43885040283203\n",
      "TIME FOR ONE GRADIENT STEP:  35.002331018447876 s\n",
      "tensor(43.7298, device='cuda:0', grad_fn=<MulBackward0>) tensor(3.4327, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "47.16253662109375\n",
      "TIME FOR ONE GRADIENT STEP:  34.446762800216675 s\n",
      "tensor(46.3551, device='cuda:0', grad_fn=<MulBackward0>) tensor(3.3769, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "49.73200988769531\n",
      "TIME FOR ONE GRADIENT STEP:  34.34662461280823 s\n",
      "tensor(46.5177, device='cuda:0', grad_fn=<MulBackward0>) tensor(3.1227, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "49.640419006347656\n",
      "TIME FOR ONE GRADIENT STEP:  34.650388956069946 s\n",
      "tensor(55.9196, device='cuda:0', grad_fn=<MulBackward0>) tensor(2.7533, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "58.67288589477539\n",
      "TIME FOR ONE GRADIENT STEP:  34.60707330703735 s\n",
      "tensor(52.6898, device='cuda:0', grad_fn=<MulBackward0>) tensor(2.4183, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "55.10814666748047\n",
      "TIME FOR ONE GRADIENT STEP:  34.60323238372803 s\n",
      "tensor(58.8508, device='cuda:0', grad_fn=<MulBackward0>) tensor(2.0928, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "60.943538665771484\n",
      "TIME FOR ONE GRADIENT STEP:  34.440863847732544 s\n",
      "tensor(54.6148, device='cuda:0', grad_fn=<MulBackward0>) tensor(1.9678, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "56.582637786865234\n",
      "TIME FOR ONE GRADIENT STEP:  34.368003606796265 s\n",
      "tensor(51.8965, device='cuda:0', grad_fn=<MulBackward0>) tensor(1.7958, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "53.692317962646484\n",
      "TIME FOR ONE GRADIENT STEP:  34.4045569896698 s\n",
      "tensor(59.5515, device='cuda:0', grad_fn=<MulBackward0>) tensor(1.6912, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "61.242740631103516\n",
      "TIME FOR ONE GRADIENT STEP:  34.175183057785034 s\n",
      "tensor(48.8587, device='cuda:0', grad_fn=<MulBackward0>) tensor(1.5945, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "50.45323944091797\n",
      "TIME FOR ONE GRADIENT STEP:  34.27403211593628 s\n",
      "tensor(57.4710, device='cuda:0', grad_fn=<MulBackward0>) tensor(1.5293, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "59.00032424926758\n",
      "TIME FOR ONE GRADIENT STEP:  34.32132911682129 s\n",
      "tensor(51.1525, device='cuda:0', grad_fn=<MulBackward0>) tensor(1.4338, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "52.586341857910156\n",
      "TIME FOR ONE GRADIENT STEP:  34.28246784210205 s\n",
      "tensor(51.6208, device='cuda:0', grad_fn=<MulBackward0>) tensor(1.4682, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "53.08892822265625\n",
      "TIME FOR ONE GRADIENT STEP:  34.390841484069824 s\n",
      "tensor(52.4564, device='cuda:0', grad_fn=<MulBackward0>) tensor(1.6517, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "54.10805892944336\n",
      "TIME FOR ONE GRADIENT STEP:  34.3057975769043 s\n",
      "tensor(52.4550, device='cuda:0', grad_fn=<MulBackward0>) tensor(1.8966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "54.351585388183594\n",
      "TIME FOR ONE GRADIENT STEP:  34.44084715843201 s\n",
      "tensor(49.9522, device='cuda:0', grad_fn=<MulBackward0>) tensor(2.1437, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "52.09589767456055\n",
      "TIME FOR ONE GRADIENT STEP:  34.31699323654175 s\n",
      "tensor(55.5203, device='cuda:0', grad_fn=<MulBackward0>) tensor(2.3716, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "57.891910552978516\n",
      "TIME FOR ONE GRADIENT STEP:  34.575273513793945 s\n",
      "tensor(50.0943, device='cuda:0', grad_fn=<MulBackward0>) tensor(2.5963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "52.690616607666016\n",
      "TIME FOR ONE GRADIENT STEP:  34.39372134208679 s\n",
      "tensor(48.8090, device='cuda:0', grad_fn=<MulBackward0>) tensor(2.6978, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "51.50677490234375\n",
      "TIME FOR ONE GRADIENT STEP:  34.31402611732483 s\n",
      "tensor(57.7471, device='cuda:0', grad_fn=<MulBackward0>) tensor(2.6895, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "60.43660354614258\n",
      "TIME FOR ONE GRADIENT STEP:  34.30113244056702 s\n",
      "tensor(52.3323, device='cuda:0', grad_fn=<MulBackward0>) tensor(2.6114, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "54.94371795654297\n",
      "TIME FOR ONE GRADIENT STEP:  34.28144407272339 s\n",
      "tensor(50.5778, device='cuda:0', grad_fn=<MulBackward0>) tensor(2.5371, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "53.11487579345703\n",
      "TIME FOR ONE GRADIENT STEP:  34.270285844802856 s\n",
      "tensor(50.5689, device='cuda:0', grad_fn=<MulBackward0>) tensor(2.6210, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "53.18989562988281\n",
      "TIME FOR ONE GRADIENT STEP:  34.347562074661255 s\n",
      "tensor(48.0086, device='cuda:0', grad_fn=<MulBackward0>) tensor(2.7044, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "50.71302795410156\n",
      "TIME FOR ONE GRADIENT STEP:  34.44517636299133 s\n",
      "tensor(47.9483, device='cuda:0', grad_fn=<MulBackward0>) tensor(2.7342, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "50.68242263793945\n",
      "TIME FOR ONE GRADIENT STEP:  34.381739377975464 s\n",
      "tensor(45.7940, device='cuda:0', grad_fn=<MulBackward0>) tensor(2.7135, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "48.507469177246094\n",
      "TIME FOR ONE GRADIENT STEP:  34.23193717002869 s\n",
      "tensor(53.2189, device='cuda:0', grad_fn=<MulBackward0>) tensor(2.6175, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "55.83637237548828\n",
      "TIME FOR ONE GRADIENT STEP:  34.288493156433105 s\n",
      "tensor(54.1660, device='cuda:0', grad_fn=<MulBackward0>) tensor(2.5532, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "56.719146728515625\n",
      "TIME FOR ONE GRADIENT STEP:  34.394145011901855 s\n",
      "tensor(44.1386, device='cuda:0', grad_fn=<MulBackward0>) tensor(2.4881, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "46.62665939331055\n",
      "TIME FOR ONE GRADIENT STEP:  34.26724863052368 s\n",
      "tensor(46.3979, device='cuda:0', grad_fn=<MulBackward0>) tensor(2.4283, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "48.8261604309082\n",
      "TIME FOR ONE GRADIENT STEP:  34.424668312072754 s\n",
      "tensor(46.0247, device='cuda:0', grad_fn=<MulBackward0>) tensor(2.7909, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "48.815582275390625\n",
      "TIME FOR ONE GRADIENT STEP:  34.25277662277222 s\n",
      "tensor(53.7699, device='cuda:0', grad_fn=<MulBackward0>) tensor(3.2221, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "56.99195098876953\n",
      "TIME FOR ONE GRADIENT STEP:  34.26926136016846 s\n",
      "tensor(48.4145, device='cuda:0', grad_fn=<MulBackward0>) tensor(3.5838, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "51.998252868652344\n",
      "TIME FOR ONE GRADIENT STEP:  34.58672475814819 s\n",
      "tensor(45.5909, device='cuda:0', grad_fn=<MulBackward0>) tensor(3.8410, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "49.431907653808594\n",
      "TIME FOR ONE GRADIENT STEP:  34.32435417175293 s\n",
      "tensor(39.5589, device='cuda:0', grad_fn=<MulBackward0>) tensor(3.9549, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "43.513816833496094\n",
      "TIME FOR ONE GRADIENT STEP:  34.63075590133667 s\n",
      "tensor(55.2106, device='cuda:0', grad_fn=<MulBackward0>) tensor(3.9551, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "59.16568374633789\n",
      "TIME FOR ONE GRADIENT STEP:  34.682915687561035 s\n",
      "tensor(52.3031, device='cuda:0', grad_fn=<MulBackward0>) tensor(3.9661, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "56.26919174194336\n",
      "TIME FOR ONE GRADIENT STEP:  34.613404989242554 s\n",
      "tensor(51.1906, device='cuda:0', grad_fn=<MulBackward0>) tensor(3.9704, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "55.160980224609375\n",
      "TIME FOR ONE GRADIENT STEP:  34.50345540046692 s\n",
      "tensor(47.3766, device='cuda:0', grad_fn=<MulBackward0>) tensor(3.9044, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "51.281036376953125\n",
      "TIME FOR ONE GRADIENT STEP:  34.4890296459198 s\n",
      "tensor(54.0928, device='cuda:0', grad_fn=<MulBackward0>) tensor(3.8668, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "57.95960235595703\n",
      "TIME FOR ONE GRADIENT STEP:  34.386279821395874 s\n",
      "tensor(44.1295, device='cuda:0', grad_fn=<MulBackward0>) tensor(4.0534, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "48.1828727722168\n",
      "TIME FOR ONE GRADIENT STEP:  34.7075719833374 s\n",
      "tensor(46.9063, device='cuda:0', grad_fn=<MulBackward0>) tensor(4.0941, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "51.00046157836914\n",
      "TIME FOR ONE GRADIENT STEP:  34.81116008758545 s\n",
      "tensor(53.9901, device='cuda:0', grad_fn=<MulBackward0>) tensor(4.0055, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "57.99561309814453\n",
      "TIME FOR ONE GRADIENT STEP:  34.394784450531006 s\n",
      "tensor(50.8868, device='cuda:0', grad_fn=<MulBackward0>) tensor(3.9589, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "54.84567642211914\n",
      "TIME FOR ONE GRADIENT STEP:  34.72795128822327 s\n",
      "tensor(43.2163, device='cuda:0', grad_fn=<MulBackward0>) tensor(3.8556, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "47.07185363769531\n",
      "TIME FOR ONE GRADIENT STEP:  34.721129179000854 s\n",
      "tensor(47.1176, device='cuda:0', grad_fn=<MulBackward0>) tensor(3.7940, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "50.9116096496582\n",
      "TIME FOR ONE GRADIENT STEP:  34.944034576416016 s\n",
      "tensor(51.4858, device='cuda:0', grad_fn=<MulBackward0>) tensor(3.3870, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "54.87279510498047\n",
      "TIME FOR ONE GRADIENT STEP:  35.03193116188049 s\n",
      "tensor(44.4296, device='cuda:0', grad_fn=<MulBackward0>) tensor(3.0051, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "47.43463897705078\n",
      "TIME FOR ONE GRADIENT STEP:  34.95631790161133 s\n",
      "tensor(51.5340, device='cuda:0', grad_fn=<MulBackward0>) tensor(2.7595, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "54.293479919433594\n",
      "TIME FOR ONE GRADIENT STEP:  34.63199281692505 s\n",
      "tensor(43.1812, device='cuda:0', grad_fn=<MulBackward0>) tensor(2.5374, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "45.71866226196289\n",
      "TIME FOR ONE GRADIENT STEP:  35.111626386642456 s\n",
      "tensor(49.6686, device='cuda:0', grad_fn=<MulBackward0>) tensor(2.3460, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "52.01461410522461\n",
      "TIME FOR ONE GRADIENT STEP:  34.984254360198975 s\n",
      "tensor(44.6970, device='cuda:0', grad_fn=<MulBackward0>) tensor(2.2347, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "46.931640625\n",
      "TIME FOR ONE GRADIENT STEP:  34.99175190925598 s\n",
      "tensor(47.9980, device='cuda:0', grad_fn=<MulBackward0>) tensor(2.1132, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "50.11121368408203\n",
      "TIME FOR ONE GRADIENT STEP:  34.96442246437073 s\n",
      "tensor(56.9278, device='cuda:0', grad_fn=<MulBackward0>) tensor(2.1129, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "59.04065704345703\n",
      "TIME FOR ONE GRADIENT STEP:  35.06725072860718 s\n",
      "tensor(53.2347, device='cuda:0', grad_fn=<MulBackward0>) tensor(2.1390, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "55.373661041259766\n",
      "TIME FOR ONE GRADIENT STEP:  34.788146018981934 s\n",
      "tensor(44.0556, device='cuda:0', grad_fn=<MulBackward0>) tensor(2.2367, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "46.29230880737305\n",
      "TIME FOR ONE GRADIENT STEP:  34.884525299072266 s\n",
      "tensor(48.7981, device='cuda:0', grad_fn=<MulBackward0>) tensor(2.2562, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "51.054344177246094\n",
      "TIME FOR ONE GRADIENT STEP:  34.354183197021484 s\n",
      "tensor(41.7919, device='cuda:0', grad_fn=<MulBackward0>) tensor(2.3357, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "44.127647399902344\n",
      "TIME FOR ONE GRADIENT STEP:  34.30483818054199 s\n",
      "tensor(51.4820, device='cuda:0', grad_fn=<MulBackward0>) tensor(2.3856, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "53.867576599121094\n",
      "TIME FOR ONE GRADIENT STEP:  34.385860204696655 s\n",
      "tensor(57.8185, device='cuda:0', grad_fn=<MulBackward0>) tensor(2.4201, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "60.23854064941406\n",
      "TIME FOR ONE GRADIENT STEP:  34.48574709892273 s\n",
      "tensor(47.7665, device='cuda:0', grad_fn=<MulBackward0>) tensor(2.4411, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "50.20758056640625\n",
      "TIME FOR ONE GRADIENT STEP:  34.4446337223053 s\n",
      "tensor(55.3796, device='cuda:0', grad_fn=<MulBackward0>) tensor(2.5192, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "57.898807525634766\n",
      "TIME FOR ONE GRADIENT STEP:  34.97700071334839 s\n",
      "tensor(51.6511, device='cuda:0', grad_fn=<MulBackward0>) tensor(2.7788, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "54.429901123046875\n",
      "TIME FOR ONE GRADIENT STEP:  35.284022092819214 s\n",
      "tensor(49.0686, device='cuda:0', grad_fn=<MulBackward0>) tensor(3.1979, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "52.26652145385742\n",
      "TIME FOR ONE GRADIENT STEP:  34.96393871307373 s\n",
      "tensor(49.0392, device='cuda:0', grad_fn=<MulBackward0>) tensor(3.6523, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "52.69157409667969\n",
      "TIME FOR ONE GRADIENT STEP:  34.841012954711914 s\n",
      "tensor(48.4358, device='cuda:0', grad_fn=<MulBackward0>) tensor(4.0432, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "52.47902297973633\n",
      "TIME FOR ONE GRADIENT STEP:  34.77302074432373 s\n",
      "tensor(46.6458, device='cuda:0', grad_fn=<MulBackward0>) tensor(4.6055, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "51.251304626464844\n",
      "TIME FOR ONE GRADIENT STEP:  34.87216782569885 s\n",
      "tensor(43.2162, device='cuda:0', grad_fn=<MulBackward0>) tensor(5.3538, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "48.569915771484375\n",
      "TIME FOR ONE GRADIENT STEP:  34.81764626502991 s\n",
      "tensor(41.6902, device='cuda:0', grad_fn=<MulBackward0>) tensor(5.8265, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "47.51670455932617\n",
      "TIME FOR ONE GRADIENT STEP:  34.85727095603943 s\n",
      "tensor(39.6094, device='cuda:0', grad_fn=<MulBackward0>) tensor(6.0440, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "45.65335464477539\n",
      "TIME FOR ONE GRADIENT STEP:  35.134382486343384 s\n",
      "tensor(49.9077, device='cuda:0', grad_fn=<MulBackward0>) tensor(6.1754, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "56.08314514160156\n",
      "TIME FOR ONE GRADIENT STEP:  34.660054445266724 s\n",
      "tensor(46.9458, device='cuda:0', grad_fn=<MulBackward0>) tensor(5.9371, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "52.882957458496094\n",
      "TIME FOR ONE GRADIENT STEP:  34.6407949924469 s\n",
      "tensor(44.8192, device='cuda:0', grad_fn=<MulBackward0>) tensor(5.7072, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "50.52642059326172\n",
      "TIME FOR ONE GRADIENT STEP:  34.685060024261475 s\n",
      "tensor(41.4944, device='cuda:0', grad_fn=<MulBackward0>) tensor(5.4427, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "46.937042236328125\n",
      "TIME FOR ONE GRADIENT STEP:  34.566691398620605 s\n",
      "tensor(40.9326, device='cuda:0', grad_fn=<MulBackward0>) tensor(5.0619, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "45.994483947753906\n",
      "TIME FOR ONE GRADIENT STEP:  34.76374363899231 s\n",
      "tensor(44.1595, device='cuda:0', grad_fn=<MulBackward0>) tensor(5.2019, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "49.361392974853516\n",
      "TIME FOR ONE GRADIENT STEP:  34.76952004432678 s\n",
      "tensor(47.0454, device='cuda:0', grad_fn=<MulBackward0>) tensor(5.2491, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "52.294410705566406\n",
      "TIME FOR ONE GRADIENT STEP:  34.83655071258545 s\n",
      "tensor(46.9990, device='cuda:0', grad_fn=<MulBackward0>) tensor(5.2477, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "52.24665451049805\n",
      "TIME FOR ONE GRADIENT STEP:  34.77790808677673 s\n",
      "tensor(42.4167, device='cuda:0', grad_fn=<MulBackward0>) tensor(5.2281, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "47.64479064941406\n",
      "TIME FOR ONE GRADIENT STEP:  34.85567283630371 s\n",
      "tensor(39.1846, device='cuda:0', grad_fn=<MulBackward0>) tensor(5.1081, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "44.292701721191406\n",
      "TIME FOR ONE GRADIENT STEP:  34.729010343551636 s\n",
      "tensor(46.0949, device='cuda:0', grad_fn=<MulBackward0>) tensor(5.1480, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "51.24294662475586\n",
      "TIME FOR ONE GRADIENT STEP:  34.69993257522583 s\n",
      "tensor(44.4129, device='cuda:0', grad_fn=<MulBackward0>) tensor(5.2011, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "49.614036560058594\n",
      "TIME FOR ONE GRADIENT STEP:  34.64169669151306 s\n",
      "tensor(40.1619, device='cuda:0', grad_fn=<MulBackward0>) tensor(5.4415, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "45.603397369384766\n",
      "TIME FOR ONE GRADIENT STEP:  34.53730273246765 s\n",
      "tensor(50.1065, device='cuda:0', grad_fn=<MulBackward0>) tensor(5.6450, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "55.75149917602539\n",
      "TIME FOR ONE GRADIENT STEP:  34.82191228866577 s\n",
      "tensor(36.3115, device='cuda:0', grad_fn=<MulBackward0>) tensor(5.9108, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "42.22232437133789\n",
      "TIME FOR ONE GRADIENT STEP:  35.1176815032959 s\n",
      "tensor(39.3740, device='cuda:0', grad_fn=<MulBackward0>) tensor(6.1413, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "45.5152702331543\n",
      "TIME FOR ONE GRADIENT STEP:  34.71601986885071 s\n",
      "tensor(40.8802, device='cuda:0', grad_fn=<MulBackward0>) tensor(6.2633, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "47.143516540527344\n",
      "TIME FOR ONE GRADIENT STEP:  34.94315958023071 s\n",
      "tensor(41.7220, device='cuda:0', grad_fn=<MulBackward0>) tensor(6.1636, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "47.885581970214844\n",
      "TIME FOR ONE GRADIENT STEP:  34.723575830459595 s\n",
      "tensor(45.3166, device='cuda:0', grad_fn=<MulBackward0>) tensor(5.9205, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "51.23711013793945\n",
      "TIME FOR ONE GRADIENT STEP:  35.049224615097046 s\n",
      "tensor(39.0492, device='cuda:0', grad_fn=<MulBackward0>) tensor(5.2572, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "44.306427001953125\n",
      "TIME FOR ONE GRADIENT STEP:  34.32705998420715 s\n",
      "tensor(43.3287, device='cuda:0', grad_fn=<MulBackward0>) tensor(5.1068, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "48.435447692871094\n",
      "TIME FOR ONE GRADIENT STEP:  34.34384751319885 s\n",
      "tensor(51.6452, device='cuda:0', grad_fn=<MulBackward0>) tensor(4.6477, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "56.29288864135742\n",
      "TIME FOR ONE GRADIENT STEP:  34.66778826713562 s\n",
      "tensor(43.7411, device='cuda:0', grad_fn=<MulBackward0>) tensor(5.4179, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "49.15898132324219\n",
      "TIME FOR ONE GRADIENT STEP:  34.84235715866089 s\n",
      "tensor(40.1431, device='cuda:0', grad_fn=<MulBackward0>) tensor(5.8447, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "45.98777770996094\n",
      "TIME FOR ONE GRADIENT STEP:  34.765814781188965 s\n",
      "tensor(42.5214, device='cuda:0', grad_fn=<MulBackward0>) tensor(5.8640, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "48.38536834716797\n",
      "TIME FOR ONE GRADIENT STEP:  34.65316557884216 s\n",
      "tensor(42.3010, device='cuda:0', grad_fn=<MulBackward0>) tensor(5.6620, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "47.96296310424805\n",
      "TIME FOR ONE GRADIENT STEP:  34.6850528717041 s\n",
      "tensor(40.0202, device='cuda:0', grad_fn=<MulBackward0>) tensor(5.7067, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "45.726966857910156\n",
      "TIME FOR ONE GRADIENT STEP:  34.361770153045654 s\n",
      "tensor(41.9584, device='cuda:0', grad_fn=<MulBackward0>) tensor(5.8072, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "47.765628814697266\n",
      "TIME FOR ONE GRADIENT STEP:  34.574172496795654 s\n",
      "tensor(33.1423, device='cuda:0', grad_fn=<MulBackward0>) tensor(5.7298, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "38.87207794189453\n",
      "TIME FOR ONE GRADIENT STEP:  35.098270893096924 s\n",
      "tensor(42.8096, device='cuda:0', grad_fn=<MulBackward0>) tensor(5.5269, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "48.33653259277344\n",
      "TIME FOR ONE GRADIENT STEP:  34.90443134307861 s\n",
      "tensor(41.8129, device='cuda:0', grad_fn=<MulBackward0>) tensor(5.4833, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "47.296207427978516\n",
      "TIME FOR ONE GRADIENT STEP:  34.604583501815796 s\n",
      "tensor(41.4920, device='cuda:0', grad_fn=<MulBackward0>) tensor(5.6059, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "47.09791564941406\n",
      "TIME FOR ONE GRADIENT STEP:  34.334357261657715 s\n",
      "tensor(38.9140, device='cuda:0', grad_fn=<MulBackward0>) tensor(5.7807, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "44.69468307495117\n",
      "TIME FOR ONE GRADIENT STEP:  34.76493692398071 s\n",
      "tensor(37.4384, device='cuda:0', grad_fn=<MulBackward0>) tensor(6.1084, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "43.54672622680664\n",
      "TIME FOR ONE GRADIENT STEP:  34.64657711982727 s\n",
      "tensor(42.3213, device='cuda:0', grad_fn=<MulBackward0>) tensor(6.3563, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "48.677650451660156\n",
      "TIME FOR ONE GRADIENT STEP:  34.43861627578735 s\n",
      "tensor(41.1561, device='cuda:0', grad_fn=<MulBackward0>) tensor(6.4826, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "47.63866424560547\n",
      "TIME FOR ONE GRADIENT STEP:  34.46329045295715 s\n",
      "tensor(40.4118, device='cuda:0', grad_fn=<MulBackward0>) tensor(6.4097, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "46.8215217590332\n",
      "TIME FOR ONE GRADIENT STEP:  34.47524809837341 s\n",
      "tensor(39.8885, device='cuda:0', grad_fn=<MulBackward0>) tensor(6.6535, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "46.541996002197266\n",
      "TIME FOR ONE GRADIENT STEP:  34.80273723602295 s\n",
      "tensor(35.0219, device='cuda:0', grad_fn=<MulBackward0>) tensor(6.6294, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "41.65126037597656\n",
      "TIME FOR ONE GRADIENT STEP:  34.34860920906067 s\n",
      "tensor(41.7030, device='cuda:0', grad_fn=<MulBackward0>) tensor(6.8555, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "48.55848693847656\n",
      "TIME FOR ONE GRADIENT STEP:  34.44820833206177 s\n",
      "tensor(37.2386, device='cuda:0', grad_fn=<MulBackward0>) tensor(7.1676, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "44.40615463256836\n",
      "TIME FOR ONE GRADIENT STEP:  34.26519536972046 s\n",
      "tensor(41.4841, device='cuda:0', grad_fn=<MulBackward0>) tensor(7.3278, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "48.81192398071289\n",
      "TIME FOR ONE GRADIENT STEP:  34.73526740074158 s\n",
      "tensor(40.4457, device='cuda:0', grad_fn=<MulBackward0>) tensor(7.2253, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "47.67100143432617\n",
      "TIME FOR ONE GRADIENT STEP:  34.958606243133545 s\n",
      "tensor(38.3330, device='cuda:0', grad_fn=<MulBackward0>) tensor(6.9091, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "45.24201202392578\n",
      "TIME FOR ONE GRADIENT STEP:  34.63702750205994 s\n",
      "tensor(42.9254, device='cuda:0', grad_fn=<MulBackward0>) tensor(6.5634, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "49.48878479003906\n",
      "TIME FOR ONE GRADIENT STEP:  34.507718563079834 s\n",
      "tensor(35.4051, device='cuda:0', grad_fn=<MulBackward0>) tensor(7.0715, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "42.476627349853516\n",
      "TIME FOR ONE GRADIENT STEP:  34.60775804519653 s\n",
      "tensor(36.9130, device='cuda:0', grad_fn=<MulBackward0>) tensor(8.6161, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "45.529083251953125\n",
      "TIME FOR ONE GRADIENT STEP:  34.7125301361084 s\n",
      "tensor(37.6332, device='cuda:0', grad_fn=<MulBackward0>) tensor(10.2408, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "47.873924255371094\n",
      "TIME FOR ONE GRADIENT STEP:  34.502866983413696 s\n",
      "tensor(31.6688, device='cuda:0', grad_fn=<MulBackward0>) tensor(11.9027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "43.57145690917969\n",
      "TIME FOR ONE GRADIENT STEP:  34.613595962524414 s\n",
      "tensor(31.6287, device='cuda:0', grad_fn=<MulBackward0>) tensor(12.4243, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "44.05305862426758\n",
      "TIME FOR ONE GRADIENT STEP:  34.56918120384216 s\n",
      "tensor(31.5506, device='cuda:0', grad_fn=<MulBackward0>) tensor(12.8476, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "44.398162841796875\n",
      "TIME FOR ONE GRADIENT STEP:  34.55951189994812 s\n",
      "tensor(29.9329, device='cuda:0', grad_fn=<MulBackward0>) tensor(11.8420, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "41.77482986450195\n",
      "TIME FOR ONE GRADIENT STEP:  34.40229392051697 s\n",
      "tensor(41.6178, device='cuda:0', grad_fn=<MulBackward0>) tensor(8.0817, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "49.69957733154297\n",
      "TIME FOR ONE GRADIENT STEP:  34.4330677986145 s\n",
      "tensor(48.6416, device='cuda:0', grad_fn=<MulBackward0>) tensor(5.9241, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "54.56571578979492\n",
      "TIME FOR ONE GRADIENT STEP:  34.48833417892456 s\n",
      "tensor(38.3624, device='cuda:0', grad_fn=<MulBackward0>) tensor(6.3005, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "44.662899017333984\n",
      "TIME FOR ONE GRADIENT STEP:  34.44523811340332 s\n",
      "tensor(45.4046, device='cuda:0', grad_fn=<MulBackward0>) tensor(7.8478, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "53.252464294433594\n",
      "TIME FOR ONE GRADIENT STEP:  34.35465145111084 s\n",
      "tensor(36.4041, device='cuda:0', grad_fn=<MulBackward0>) tensor(11.8519, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "48.25594711303711\n",
      "TIME FOR ONE GRADIENT STEP:  34.534175634384155 s\n",
      "tensor(34.7369, device='cuda:0', grad_fn=<MulBackward0>) tensor(13.6481, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "48.38494110107422\n",
      "TIME FOR ONE GRADIENT STEP:  34.57821726799011 s\n",
      "tensor(28.3941, device='cuda:0', grad_fn=<MulBackward0>) tensor(14.9769, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "43.37104034423828\n",
      "TIME FOR ONE GRADIENT STEP:  34.547571420669556 s\n",
      "tensor(28.0443, device='cuda:0', grad_fn=<MulBackward0>) tensor(14.9834, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "43.0277214050293\n",
      "TIME FOR ONE GRADIENT STEP:  34.57165813446045 s\n",
      "tensor(30.8190, device='cuda:0', grad_fn=<MulBackward0>) tensor(15.7721, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "46.59113693237305\n",
      "TIME FOR ONE GRADIENT STEP:  34.715872287750244 s\n",
      "tensor(26.5512, device='cuda:0', grad_fn=<MulBackward0>) tensor(15.6052, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "42.15637969970703\n",
      "TIME FOR ONE GRADIENT STEP:  34.625537157058716 s\n",
      "tensor(27.8297, device='cuda:0', grad_fn=<MulBackward0>) tensor(15.0211, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "42.850799560546875\n",
      "TIME FOR ONE GRADIENT STEP:  34.67029547691345 s\n",
      "tensor(29.7559, device='cuda:0', grad_fn=<MulBackward0>) tensor(14.2684, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "44.024234771728516\n",
      "TIME FOR ONE GRADIENT STEP:  34.2175931930542 s\n",
      "tensor(37.3840, device='cuda:0', grad_fn=<MulBackward0>) tensor(13.2283, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "50.612274169921875\n",
      "TIME FOR ONE GRADIENT STEP:  34.49174380302429 s\n",
      "tensor(25.1520, device='cuda:0', grad_fn=<MulBackward0>) tensor(12.0918, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "37.24384307861328\n",
      "TIME FOR ONE GRADIENT STEP:  34.476990938186646 s\n",
      "tensor(33.8946, device='cuda:0', grad_fn=<MulBackward0>) tensor(10.8813, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "44.775875091552734\n",
      "TIME FOR ONE GRADIENT STEP:  34.40423321723938 s\n",
      "tensor(33.0061, device='cuda:0', grad_fn=<MulBackward0>) tensor(9.6416, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "42.647621154785156\n",
      "TIME FOR ONE GRADIENT STEP:  34.45117807388306 s\n",
      "tensor(44.8870, device='cuda:0', grad_fn=<MulBackward0>) tensor(8.9318, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "53.8187370300293\n",
      "TIME FOR ONE GRADIENT STEP:  34.435579776763916 s\n",
      "tensor(37.7513, device='cuda:0', grad_fn=<MulBackward0>) tensor(8.3218, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "46.07311248779297\n",
      "TIME FOR ONE GRADIENT STEP:  34.32577848434448 s\n",
      "tensor(33.5568, device='cuda:0', grad_fn=<MulBackward0>) tensor(7.7857, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "41.34251403808594\n",
      "TIME FOR ONE GRADIENT STEP:  34.517181158065796 s\n",
      "tensor(37.7678, device='cuda:0', grad_fn=<MulBackward0>) tensor(7.3046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "45.0723876953125\n",
      "TIME FOR ONE GRADIENT STEP:  34.54441452026367 s\n",
      "tensor(32.9777, device='cuda:0', grad_fn=<MulBackward0>) tensor(7.0107, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "39.98839569091797\n",
      "TIME FOR ONE GRADIENT STEP:  34.23709177970886 s\n",
      "tensor(38.5811, device='cuda:0', grad_fn=<MulBackward0>) tensor(6.4333, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "45.01435089111328\n",
      "TIME FOR ONE GRADIENT STEP:  34.451913833618164 s\n",
      "tensor(39.9435, device='cuda:0', grad_fn=<MulBackward0>) tensor(5.9654, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "45.90892028808594\n",
      "TIME FOR ONE GRADIENT STEP:  34.71294713020325 s\n",
      "tensor(41.0419, device='cuda:0', grad_fn=<MulBackward0>) tensor(6.1394, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "47.181358337402344\n",
      "TIME FOR ONE GRADIENT STEP:  34.62841534614563 s\n",
      "tensor(34.8440, device='cuda:0', grad_fn=<MulBackward0>) tensor(6.2583, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "41.10224533081055\n",
      "TIME FOR ONE GRADIENT STEP:  34.370208740234375 s\n",
      "tensor(42.2397, device='cuda:0', grad_fn=<MulBackward0>) tensor(6.3731, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "48.61279296875\n",
      "TIME FOR ONE GRADIENT STEP:  34.281126976013184 s\n",
      "tensor(44.7048, device='cuda:0', grad_fn=<MulBackward0>) tensor(6.5167, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "51.221439361572266\n",
      "TIME FOR ONE GRADIENT STEP:  34.517903566360474 s\n",
      "tensor(39.0376, device='cuda:0', grad_fn=<MulBackward0>) tensor(6.7940, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "45.8315544128418\n",
      "TIME FOR ONE GRADIENT STEP:  34.80063986778259 s\n",
      "tensor(36.7196, device='cuda:0', grad_fn=<MulBackward0>) tensor(7.0063, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "43.72592544555664\n",
      "TIME FOR ONE GRADIENT STEP:  34.333361864089966 s\n",
      "tensor(37.0658, device='cuda:0', grad_fn=<MulBackward0>) tensor(7.1192, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "44.185035705566406\n",
      "TIME FOR ONE GRADIENT STEP:  34.18970489501953 s\n",
      "tensor(39.3490, device='cuda:0', grad_fn=<MulBackward0>) tensor(7.3708, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "46.719818115234375\n",
      "TIME FOR ONE GRADIENT STEP:  34.553295612335205 s\n",
      "tensor(42.9904, device='cuda:0', grad_fn=<MulBackward0>) tensor(7.6332, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "50.623558044433594\n",
      "TIME FOR ONE GRADIENT STEP:  34.43790888786316 s\n",
      "tensor(34.1749, device='cuda:0', grad_fn=<MulBackward0>) tensor(8.0790, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "42.253807067871094\n",
      "TIME FOR ONE GRADIENT STEP:  34.076671838760376 s\n",
      "tensor(40.2962, device='cuda:0', grad_fn=<MulBackward0>) tensor(8.3707, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "48.66687774658203\n",
      "TIME FOR ONE GRADIENT STEP:  34.52656269073486 s\n",
      "tensor(31.9228, device='cuda:0', grad_fn=<MulBackward0>) tensor(8.5411, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "40.463829040527344\n",
      "TIME FOR ONE GRADIENT STEP:  34.42897272109985 s\n",
      "tensor(34.4866, device='cuda:0', grad_fn=<MulBackward0>) tensor(8.7168, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "43.20336151123047\n",
      "TIME FOR ONE GRADIENT STEP:  34.06342124938965 s\n",
      "tensor(41.7265, device='cuda:0', grad_fn=<MulBackward0>) tensor(8.5109, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "50.23745346069336\n",
      "TIME FOR ONE GRADIENT STEP:  34.65729832649231 s\n",
      "tensor(35.6909, device='cuda:0', grad_fn=<MulBackward0>) tensor(8.4577, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "44.14863586425781\n",
      "TIME FOR ONE GRADIENT STEP:  34.91731595993042 s\n",
      "tensor(34.6080, device='cuda:0', grad_fn=<MulBackward0>) tensor(8.2018, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "42.809730529785156\n",
      "TIME FOR ONE GRADIENT STEP:  34.665189266204834 s\n",
      "tensor(39.7976, device='cuda:0', grad_fn=<MulBackward0>) tensor(8.2168, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "48.01442337036133\n",
      "TIME FOR ONE GRADIENT STEP:  34.86880016326904 s\n",
      "tensor(41.9708, device='cuda:0', grad_fn=<MulBackward0>) tensor(8.5634, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "50.53416061401367\n",
      "TIME FOR ONE GRADIENT STEP:  34.40482783317566 s\n",
      "tensor(38.8355, device='cuda:0', grad_fn=<MulBackward0>) tensor(8.8257, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "47.661251068115234\n",
      "TIME FOR ONE GRADIENT STEP:  34.06896615028381 s\n",
      "tensor(30.9410, device='cuda:0', grad_fn=<MulBackward0>) tensor(9.0002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "39.94116973876953\n",
      "TIME FOR ONE GRADIENT STEP:  34.45976662635803 s\n",
      "tensor(33.8108, device='cuda:0', grad_fn=<MulBackward0>) tensor(9.1006, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "42.91141128540039\n",
      "TIME FOR ONE GRADIENT STEP:  34.265024185180664 s\n",
      "tensor(29.4898, device='cuda:0', grad_fn=<MulBackward0>) tensor(9.3073, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "38.79716110229492\n",
      "TIME FOR ONE GRADIENT STEP:  34.41182279586792 s\n",
      "tensor(30.3797, device='cuda:0', grad_fn=<MulBackward0>) tensor(9.7207, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "40.10040283203125\n",
      "TIME FOR ONE GRADIENT STEP:  34.45966672897339 s\n",
      "tensor(32.5743, device='cuda:0', grad_fn=<MulBackward0>) tensor(10.0276, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "42.60191345214844\n",
      "TIME FOR ONE GRADIENT STEP:  34.36114573478699 s\n",
      "tensor(36.1242, device='cuda:0', grad_fn=<MulBackward0>) tensor(10.4872, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "46.611446380615234\n",
      "TIME FOR ONE GRADIENT STEP:  34.59951066970825 s\n",
      "tensor(27.5806, device='cuda:0', grad_fn=<MulBackward0>) tensor(10.6505, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "38.231056213378906\n",
      "TIME FOR ONE GRADIENT STEP:  34.24293398857117 s\n",
      "tensor(27.0178, device='cuda:0', grad_fn=<MulBackward0>) tensor(10.7606, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "37.77842330932617\n",
      "TIME FOR ONE GRADIENT STEP:  34.55537438392639 s\n",
      "tensor(32.5722, device='cuda:0', grad_fn=<MulBackward0>) tensor(10.7461, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "43.31827926635742\n",
      "TIME FOR ONE GRADIENT STEP:  34.316368103027344 s\n",
      "tensor(30.9929, device='cuda:0', grad_fn=<MulBackward0>) tensor(10.4790, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "41.47199630737305\n",
      "TIME FOR ONE GRADIENT STEP:  34.63531970977783 s\n",
      "tensor(33.3114, device='cuda:0', grad_fn=<MulBackward0>) tensor(10.0763, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "43.3877067565918\n",
      "TIME FOR ONE GRADIENT STEP:  34.34283518791199 s\n",
      "tensor(36.1197, device='cuda:0', grad_fn=<MulBackward0>) tensor(9.5966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "45.71629333496094\n",
      "TIME FOR ONE GRADIENT STEP:  34.35156512260437 s\n",
      "tensor(32.3682, device='cuda:0', grad_fn=<MulBackward0>) tensor(9.2370, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "41.60517120361328\n",
      "TIME FOR ONE GRADIENT STEP:  34.63386368751526 s\n",
      "tensor(33.1282, device='cuda:0', grad_fn=<MulBackward0>) tensor(8.8792, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "42.00740051269531\n",
      "TIME FOR ONE GRADIENT STEP:  34.32370686531067 s\n",
      "tensor(37.1481, device='cuda:0', grad_fn=<MulBackward0>) tensor(8.5284, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "45.676513671875\n",
      "TIME FOR ONE GRADIENT STEP:  34.731022119522095 s\n",
      "tensor(38.8520, device='cuda:0', grad_fn=<MulBackward0>) tensor(8.1496, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "47.001609802246094\n",
      "TIME FOR ONE GRADIENT STEP:  34.39428997039795 s\n",
      "tensor(36.1560, device='cuda:0', grad_fn=<MulBackward0>) tensor(7.7450, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "43.90095901489258\n",
      "TIME FOR ONE GRADIENT STEP:  34.481396198272705 s\n",
      "tensor(37.4777, device='cuda:0', grad_fn=<MulBackward0>) tensor(7.3091, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "44.78683853149414\n",
      "TIME FOR ONE GRADIENT STEP:  34.313316822052 s\n",
      "tensor(43.5997, device='cuda:0', grad_fn=<MulBackward0>) tensor(7.0441, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "50.643882751464844\n",
      "TIME FOR ONE GRADIENT STEP:  34.75667476654053 s\n",
      "tensor(32.4999, device='cuda:0', grad_fn=<MulBackward0>) tensor(6.8093, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "39.30922317504883\n",
      "TIME FOR ONE GRADIENT STEP:  34.20535659790039 s\n",
      "tensor(36.3887, device='cuda:0', grad_fn=<MulBackward0>) tensor(6.7755, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "43.164268493652344\n",
      "TIME FOR ONE GRADIENT STEP:  34.777409076690674 s\n",
      "tensor(33.9226, device='cuda:0', grad_fn=<MulBackward0>) tensor(6.8967, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "40.819278717041016\n",
      "TIME FOR ONE GRADIENT STEP:  34.280245304107666 s\n",
      "tensor(37.6142, device='cuda:0', grad_fn=<MulBackward0>) tensor(7.1016, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "44.71580123901367\n",
      "TIME FOR ONE GRADIENT STEP:  34.695335149765015 s\n",
      "tensor(30.5706, device='cuda:0', grad_fn=<MulBackward0>) tensor(7.3139, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "37.884483337402344\n",
      "TIME FOR ONE GRADIENT STEP:  34.15617632865906 s\n",
      "tensor(37.1882, device='cuda:0', grad_fn=<MulBackward0>) tensor(7.3690, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "44.55722427368164\n",
      "TIME FOR ONE GRADIENT STEP:  34.49933338165283 s\n",
      "tensor(39.0092, device='cuda:0', grad_fn=<MulBackward0>) tensor(7.5814, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "46.590606689453125\n",
      "TIME FOR ONE GRADIENT STEP:  34.10441994667053 s\n",
      "tensor(30.1650, device='cuda:0', grad_fn=<MulBackward0>) tensor(8.4780, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "38.64307403564453\n",
      "TIME FOR ONE GRADIENT STEP:  34.07774329185486 s\n",
      "tensor(32.4687, device='cuda:0', grad_fn=<MulBackward0>) tensor(9.3533, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "41.82194519042969\n",
      "TIME FOR ONE GRADIENT STEP:  34.51168489456177 s\n",
      "tensor(36.2510, device='cuda:0', grad_fn=<MulBackward0>) tensor(10.0308, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "46.28179931640625\n",
      "TIME FOR ONE GRADIENT STEP:  34.17703580856323 s\n",
      "tensor(31.2166, device='cuda:0', grad_fn=<MulBackward0>) tensor(10.5972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "41.81383514404297\n",
      "TIME FOR ONE GRADIENT STEP:  34.62911295890808 s\n",
      "tensor(31.8907, device='cuda:0', grad_fn=<MulBackward0>) tensor(11.1955, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "43.08622741699219\n",
      "TIME FOR ONE GRADIENT STEP:  34.219993114471436 s\n",
      "tensor(28.9583, device='cuda:0', grad_fn=<MulBackward0>) tensor(11.4885, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "40.446800231933594\n",
      "TIME FOR ONE GRADIENT STEP:  34.511559009552 s\n",
      "tensor(29.8087, device='cuda:0', grad_fn=<MulBackward0>) tensor(11.6555, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "41.46422576904297\n",
      "TIME FOR ONE GRADIENT STEP:  34.173009634017944 s\n",
      "tensor(29.1844, device='cuda:0', grad_fn=<MulBackward0>) tensor(11.6001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "40.78445053100586\n",
      "TIME FOR ONE GRADIENT STEP:  34.605111837387085 s\n",
      "tensor(32.3970, device='cuda:0', grad_fn=<MulBackward0>) tensor(11.3848, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "43.7818717956543\n",
      "TIME FOR ONE GRADIENT STEP:  34.168917417526245 s\n",
      "tensor(31.4773, device='cuda:0', grad_fn=<MulBackward0>) tensor(11.1014, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "42.578758239746094\n",
      "TIME FOR ONE GRADIENT STEP:  34.81957006454468 s\n",
      "tensor(29.8214, device='cuda:0', grad_fn=<MulBackward0>) tensor(10.8403, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "40.66172409057617\n",
      "TIME FOR ONE GRADIENT STEP:  34.38025426864624 s\n",
      "tensor(38.2254, device='cuda:0', grad_fn=<MulBackward0>) tensor(10.5303, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "48.75574493408203\n",
      "TIME FOR ONE GRADIENT STEP:  34.20314073562622 s\n",
      "tensor(28.7119, device='cuda:0', grad_fn=<MulBackward0>) tensor(10.1981, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "38.90998840332031\n",
      "TIME FOR ONE GRADIENT STEP:  35.19938135147095 s\n",
      "tensor(37.5026, device='cuda:0', grad_fn=<MulBackward0>) tensor(9.9318, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "47.434417724609375\n",
      "TIME FOR ONE GRADIENT STEP:  34.61424922943115 s\n",
      "tensor(42.3179, device='cuda:0', grad_fn=<MulBackward0>) tensor(9.6216, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "51.93954086303711\n",
      "TIME FOR ONE GRADIENT STEP:  34.7363018989563 s\n",
      "tensor(36.0787, device='cuda:0', grad_fn=<MulBackward0>) tensor(9.2409, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "45.31962966918945\n",
      "TIME FOR ONE GRADIENT STEP:  34.51173710823059 s\n",
      "tensor(40.4766, device='cuda:0', grad_fn=<MulBackward0>) tensor(8.8718, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "49.34845733642578\n",
      "TIME FOR ONE GRADIENT STEP:  35.22718644142151 s\n",
      "tensor(33.3814, device='cuda:0', grad_fn=<MulBackward0>) tensor(8.5512, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "41.93259811401367\n",
      "TIME FOR ONE GRADIENT STEP:  34.90423321723938 s\n",
      "tensor(28.4703, device='cuda:0', grad_fn=<MulBackward0>) tensor(8.2583, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "36.728553771972656\n",
      "TIME FOR ONE GRADIENT STEP:  35.00781607627869 s\n",
      "tensor(29.8928, device='cuda:0', grad_fn=<MulBackward0>) tensor(7.9285, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "37.821346282958984\n",
      "TIME FOR ONE GRADIENT STEP:  35.27489995956421 s\n",
      "tensor(33.7588, device='cuda:0', grad_fn=<MulBackward0>) tensor(7.5306, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "41.28940200805664\n",
      "TIME FOR ONE GRADIENT STEP:  34.8115816116333 s\n",
      "tensor(28.7219, device='cuda:0', grad_fn=<MulBackward0>) tensor(7.3819, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "36.103858947753906\n",
      "TIME FOR ONE GRADIENT STEP:  34.89125847816467 s\n",
      "tensor(35.0903, device='cuda:0', grad_fn=<MulBackward0>) tensor(7.2078, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "42.29814529418945\n",
      "TIME FOR ONE GRADIENT STEP:  35.17882037162781 s\n",
      "tensor(29.9253, device='cuda:0', grad_fn=<MulBackward0>) tensor(6.9269, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "36.852291107177734\n",
      "TIME FOR ONE GRADIENT STEP:  34.800949811935425 s\n",
      "tensor(32.7224, device='cuda:0', grad_fn=<MulBackward0>) tensor(6.7087, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "39.431060791015625\n",
      "TIME FOR ONE GRADIENT STEP:  34.78872847557068 s\n",
      "tensor(41.9486, device='cuda:0', grad_fn=<MulBackward0>) tensor(6.5106, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "48.4592170715332\n",
      "TIME FOR ONE GRADIENT STEP:  35.02270317077637 s\n",
      "tensor(40.8176, device='cuda:0', grad_fn=<MulBackward0>) tensor(6.3478, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "47.16537094116211\n",
      "TIME FOR ONE GRADIENT STEP:  34.641141414642334 s\n",
      "tensor(40.8847, device='cuda:0', grad_fn=<MulBackward0>) tensor(6.4088, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "47.293540954589844\n",
      "TIME FOR ONE GRADIENT STEP:  34.728705644607544 s\n",
      "tensor(39.1859, device='cuda:0', grad_fn=<MulBackward0>) tensor(6.5615, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "45.74740982055664\n",
      "TIME FOR ONE GRADIENT STEP:  35.300930976867676 s\n",
      "tensor(37.9388, device='cuda:0', grad_fn=<MulBackward0>) tensor(6.9592, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "44.89801788330078\n",
      "TIME FOR ONE GRADIENT STEP:  34.70414113998413 s\n",
      "tensor(32.5955, device='cuda:0', grad_fn=<MulBackward0>) tensor(7.5205, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "40.11598205566406\n",
      "TIME FOR ONE GRADIENT STEP:  34.87239193916321 s\n",
      "tensor(32.4461, device='cuda:0', grad_fn=<MulBackward0>) tensor(8.2078, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "40.653873443603516\n",
      "TIME FOR ONE GRADIENT STEP:  35.424997329711914 s\n",
      "tensor(41.7266, device='cuda:0', grad_fn=<MulBackward0>) tensor(8.5881, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "50.31468963623047\n",
      "TIME FOR ONE GRADIENT STEP:  34.73458552360535 s\n",
      "tensor(34.7394, device='cuda:0', grad_fn=<MulBackward0>) tensor(8.7536, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "43.492950439453125\n",
      "TIME FOR ONE GRADIENT STEP:  34.85643696784973 s\n",
      "tensor(23.5134, device='cuda:0', grad_fn=<MulBackward0>) tensor(8.9685, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "32.481964111328125\n",
      "TIME FOR ONE GRADIENT STEP:  34.62347412109375 s\n",
      "tensor(28.3585, device='cuda:0', grad_fn=<MulBackward0>) tensor(9.0608, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "37.41932678222656\n",
      "TIME FOR ONE GRADIENT STEP:  35.16191077232361 s\n",
      "tensor(29.7867, device='cuda:0', grad_fn=<MulBackward0>) tensor(8.9478, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "38.734474182128906\n",
      "TIME FOR ONE GRADIENT STEP:  34.67084336280823 s\n",
      "tensor(34.8610, device='cuda:0', grad_fn=<MulBackward0>) tensor(9.1004, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "43.961326599121094\n",
      "TIME FOR ONE GRADIENT STEP:  34.852864265441895 s\n",
      "tensor(26.5410, device='cuda:0', grad_fn=<MulBackward0>) tensor(9.1725, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "35.71352005004883\n",
      "TIME FOR ONE GRADIENT STEP:  34.6150336265564 s\n",
      "tensor(31.8701, device='cuda:0', grad_fn=<MulBackward0>) tensor(9.2181, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "41.08827209472656\n",
      "TIME FOR ONE GRADIENT STEP:  35.40562391281128 s\n",
      "tensor(26.3732, device='cuda:0', grad_fn=<MulBackward0>) tensor(9.2164, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "35.589595794677734\n",
      "TIME FOR ONE GRADIENT STEP:  34.619094371795654 s\n",
      "tensor(39.7745, device='cuda:0', grad_fn=<MulBackward0>) tensor(9.0299, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "48.804405212402344\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "sde_model = SDE(model=model, sde=sde, y_noise=y_noise)\n",
    "\n",
    "print(sde_model.parameters())\n",
    "\n",
    "print(\"PARAMETERS IN SDE MODEL: \", sum([p.numel() for p in sde_model.parameters()]))\n",
    "print(\"PARAMETERS IN pretrained model: \", sum([p.numel() for p in sde_model.model.parameters()]))\n",
    "print(\"PARAMETERS IN finetune: \", sum([p.numel() for p in sde_model.cond_model.parameters()]))\n",
    "\n",
    "\n",
    "batch_size = 12\n",
    "\n",
    "cond = torch.repeat_interleave(y_noise,  dim=0, repeats=batch_size)\n",
    "\n",
    "t_size = 200\n",
    "\n",
    "optimizer = torch.optim.Adam(sde_model.cond_model.parameters(), lr=1e-3)\n",
    "\n",
    "x_target = x_gt.repeat(batch_size, 1, 1, 1)\n",
    "\n",
    "import time \n",
    "print(x_target.shape)\n",
    "for i in range(1000):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    y0 = torch.randn((batch_size, 784)).to(\"cuda\")\n",
    "    y0 = torch.cat([y0, torch.zeros((batch_size, 1), device=y0.device)], dim=1)\n",
    "    bm = torchsde.BrownianInterval(t0=0.0, t1=1.0 - 1.e-3, size=(batch_size, 784 + 1), device='cuda')\n",
    "\n",
    "    ts = torch.linspace(0, 1 - 1.e-3, t_size).to(\"cuda\")\n",
    "\n",
    "    t_start = time.time()\n",
    "    #ys, logpq = torchsde.sdeint_adjoint(sde_model, y0, ts, method='euler', logqp=True)\n",
    "    # currently torchsde only supports equidistant time steps with non-adaptive solvers\n",
    "    ys = torchsde.sdeint_adjoint(sde_model, y0, ts, method='euler',adjoint_method=\"euler\", dt=ts[1] - ts[0]) \n",
    "    #ys = torchsde.sdeint_adjoint(sde_model, y0, ts, \n",
    "    #                method=\"reversible_heun\",\n",
    "    #                adjoint_method=\"adjoint_reversible_heun\", \n",
    "    #                dt=ts[1] - ts[0], bm=bm,\n",
    "    #                adjoint_params=sde_model.cond_model.parameters())\n",
    "\n",
    "    #print(logpq.shape)\n",
    "    ys_img = ys[-1, :, :-1]\n",
    "    ys_img = ys_img.view(batch_size, 1, 28, 28)\n",
    "\n",
    "    f_sq = ys[-1, :, -1]\n",
    "    #loss = torch.sum(logpq**2) + 1/2*torch.sum((Afwd(ys) - y_noise)**2)\n",
    "    loss_data = 1/2*torch.mean(torch.sum((Afwd(ys_img) - cond)**2, dim=1)) #1/2 * torch.mean(torch.sum((ys_img - x_target)**2, dim=(1,2,3)))\n",
    "    print(loss_data, torch.mean(f_sq))\n",
    "    loss = loss_data + torch.mean(f_sq) \n",
    "    print(loss.item())\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    t_end = time.time() \n",
    "    print(\"TIME FOR ONE GRADIENT STEP: \", t_end - t_start, \"s\")\n",
    "    fig, (ax1, ax2) = plt.subplots(1,2)\n",
    "\n",
    "\n",
    "    img_grid = make_grid(ys_img.cpu(), n_row=4)\n",
    "    ax1.set_title(f\"loss: {loss.item()}\")\n",
    "    ax1.imshow(x_target[0,0,:,:].cpu().numpy(), cmap=\"gray\")\n",
    "    ax2.imshow(img_grid[0,:,:].numpy(), cmap=\"gray\")\n",
    "    plt.savefig(f\"adjoint_test_imgs_larger/iter_{i}.png\")\n",
    "\n",
    "    plt.close()\n",
    "\n",
    "    \"\"\"\n",
    "    if i % 5 == 0:# and i > 0:\n",
    "        with torch.no_grad():\n",
    "            y0 = torch.randn((batch_size, 784)).to(\"cuda\")\n",
    "            y0 = torch.cat([y0, torch.zeros((batch_size, 1), device=y0.device)], dim=1)\n",
    "\n",
    "            ts = torch.linspace(0, 1 - 1.e-3, t_size).to(\"cuda\")\n",
    "            #ys, logpq = torchsde.sdeint_adjoint(sde_model, y0, ts, method='euler', logqp=True)\n",
    "            #ys = torchsde.sdeint_adjoint(sde_model, y0, ts, method='euler',adjoint_method=\"euler\", dt=0.01)\n",
    "            ys = torchsde.sdeint(sde_model, y0, ts, method='euler',dt=ts[1] - ts[0], bm=bm)\n",
    "\n",
    "            #print(logpq.shape)\n",
    "            ys = ys[-1, :, :-1]\n",
    "            ys = ys.view(batch_size, 1, 28, 28)\n",
    "\n",
    "        img_grid = make_grid(ys.cpu(), n_row=4)\n",
    "        #print(x_mean.shape, img_grid.shape)\n",
    "        plt.figure()\n",
    "        plt.imshow(img_grid[0,:,:].numpy(), cmap=\"gray\")\n",
    "        plt.show()\n",
    "\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53aca35d-6ddb-4b6f-b832-1936a312f122",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
